{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEXYestn6foW",
        "outputId": "777a497d-1f75-435e-bf1c-1a81f626112b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'layout-dm'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 211 (delta 14), reused 12 (delta 10), pack-reused 181\u001b[K\n",
            "Receiving objects: 100% (211/211), 1.03 MiB | 12.51 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CyberAgentAILab/layout-dm.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sSL https://install.python-poetry.org | python3 -\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TmLYfSw8Lg5",
        "outputId": "192cc408-0d19-4972-90aa-9240c0146f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36mRetrieving Poetry metadata\u001b[0m\n",
            "\n",
            "# Welcome to \u001b[36mPoetry\u001b[0m!\n",
            "\n",
            "This will download and install the latest version of \u001b[36mPoetry\u001b[0m,\n",
            "a dependency and package manager for Python.\n",
            "\n",
            "It will add the `poetry` command to \u001b[36mPoetry\u001b[0m's bin directory, located at:\n",
            "\n",
            "\u001b[33m/root/.local/bin\u001b[0m\n",
            "\n",
            "You can uninstall at any time by executing this script with the --uninstall option,\n",
            "and these changes will be reverted.\n",
            "\n",
            "Installing \u001b[36mPoetry\u001b[0m (\u001b[36m1.8.2\u001b[0m)\n",
            "\u001b[1A\u001b[2KInstalling \u001b[36mPoetry\u001b[0m (\u001b[1m1.8.2\u001b[0m): \u001b[33mCreating environment\u001b[0m\n",
            "\u001b[1A\u001b[2KInstalling \u001b[36mPoetry\u001b[0m (\u001b[1m1.8.2\u001b[0m): \u001b[33mInstalling Poetry\u001b[0m\n",
            "\u001b[1A\u001b[2KInstalling \u001b[36mPoetry\u001b[0m (\u001b[1m1.8.2\u001b[0m): \u001b[33mCreating script\u001b[0m\n",
            "\u001b[1A\u001b[2KInstalling \u001b[36mPoetry\u001b[0m (\u001b[1m1.8.2\u001b[0m): \u001b[33mDone\u001b[0m\n",
            "\n",
            "\u001b[36mPoetry\u001b[0m (\u001b[1m1.8.2\u001b[0m) is installed now. Great!\n",
            "\n",
            "To get started you need \u001b[36mPoetry\u001b[0m's bin directory (\u001b[33m/root/.local/bin\u001b[0m) in your `PATH`\n",
            "environment variable.\n",
            "\n",
            "Add `export PATH=\"\u001b[33m/root/.local/bin\u001b[0m:$PATH\"` to your shell configuration file.\n",
            "\n",
            "Alternatively, you can call \u001b[36mPoetry\u001b[0m explicitly with `\u001b[1m/root/.local/bin/poetry\u001b[0m`.\n",
            "\n",
            "You can test that everything is set up by executing:\n",
            "\n",
            "`\u001b[1mpoetry --version\u001b[0m`\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!poetry install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkU9_sCC8PnF",
        "outputId": "529e99c3-58ca-4b9a-9fb9-4b88b91a8070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: poetry: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd layout-dm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkJB8-Lb8TeK",
        "outputId": "d2066fbd-5e5e-4c51-dea3-cba2f6924cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/layout-dm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/CyberAgentAILab/layout-dm/releases/download/v1.0.0/layoutdm_starter.zip\n",
        "!unzip layoutdm_starter.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_5je3YO8YWn",
        "outputId": "9e43eb76-dd7e-47ab-a51a-4ed034a99cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-21 21:36:48--  https://github.com/CyberAgentAILab/layout-dm/releases/download/v1.0.0/layoutdm_starter.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/611164123/3a4525c8-6800-4d83-95df-2577e1880c9c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240321%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240321T213649Z&X-Amz-Expires=300&X-Amz-Signature=3462de228d0c5ecf8c6a7a109f591040ce4443319e18fef741c306729b775f78&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=611164123&response-content-disposition=attachment%3B%20filename%3Dlayoutdm_starter.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-03-21 21:36:49--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/611164123/3a4525c8-6800-4d83-95df-2577e1880c9c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240321%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240321T213649Z&X-Amz-Expires=300&X-Amz-Signature=3462de228d0c5ecf8c6a7a109f591040ce4443319e18fef741c306729b775f78&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=611164123&response-content-disposition=attachment%3B%20filename%3Dlayoutdm_starter.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 401583484 (383M) [application/octet-stream]\n",
            "Saving to: ‘layoutdm_starter.zip’\n",
            "\n",
            "layoutdm_starter.zi 100%[===================>] 382.98M   167MB/s    in 2.3s    \n",
            "\n",
            "2024-03-21 21:36:51 (167 MB/s) - ‘layoutdm_starter.zip’ saved [401583484/401583484]\n",
            "\n",
            "Archive:  layoutdm_starter.zip\n",
            "   creating: download/\n",
            "   creating: download/fid_weights/\n",
            "   creating: download/fid_weights/FIDNetV3/\n",
            "   creating: download/fid_weights/FIDNetV3/rico25-max25/\n",
            "  inflating: download/fid_weights/FIDNetV3/rico25-max25/model_best.pth.tar  \n",
            "   creating: download/fid_weights/FIDNetV3/publaynet-max25/\n",
            "  inflating: download/fid_weights/FIDNetV3/publaynet-max25/model_best.pth.tar  \n",
            "   creating: download/pretrained_weights/\n",
            "   creating: download/pretrained_weights/layoutdm_rico/\n",
            "   creating: download/pretrained_weights/layoutdm_rico/0/\n",
            "  inflating: download/pretrained_weights/layoutdm_rico/0/best_model.pt  \n",
            "  inflating: download/pretrained_weights/layoutdm_rico/0/config.yaml  \n",
            "   creating: download/pretrained_weights/layoutdm_rico/1/\n",
            "  inflating: download/pretrained_weights/layoutdm_rico/1/best_model.pt  \n",
            "  inflating: download/pretrained_weights/layoutdm_rico/1/config.yaml  \n",
            "   creating: download/pretrained_weights/layoutdm_rico/2/\n",
            "  inflating: download/pretrained_weights/layoutdm_rico/2/best_model.pt  \n",
            "  inflating: download/pretrained_weights/layoutdm_rico/2/config.yaml  \n",
            "   creating: download/pretrained_weights/layoutdm_publaynet/\n",
            "   creating: download/pretrained_weights/layoutdm_publaynet/0/\n",
            "  inflating: download/pretrained_weights/layoutdm_publaynet/0/best_model.pt  \n",
            "  inflating: download/pretrained_weights/layoutdm_publaynet/0/config.yaml  \n",
            "   creating: download/pretrained_weights/layoutdm_publaynet/1/\n",
            "  inflating: download/pretrained_weights/layoutdm_publaynet/1/best_model.pt  \n",
            "  inflating: download/pretrained_weights/layoutdm_publaynet/1/config.yaml  \n",
            "   creating: download/pretrained_weights/layoutdm_publaynet/2/\n",
            "  inflating: download/pretrained_weights/layoutdm_publaynet/2/best_model.pt  \n",
            "  inflating: download/pretrained_weights/layoutdm_publaynet/2/config.yaml  \n",
            "   creating: download/datasets/\n",
            "   creating: download/datasets/rico25-max25/\n",
            "   creating: download/datasets/rico25-max25/processed/\n",
            "  inflating: download/datasets/rico25-max25/processed/pre_transform.pt  \n",
            "  inflating: download/datasets/rico25-max25/processed/val.pt  \n",
            "  inflating: download/datasets/rico25-max25/processed/test.pt  \n",
            "  inflating: download/datasets/rico25-max25/processed/train.pt  \n",
            "  inflating: download/datasets/rico25-max25/processed/pre_filter.pt  \n",
            "   creating: download/datasets/rico25-max25/raw/\n",
            "   creating: download/datasets/publaynet-max25/\n",
            "   creating: download/datasets/publaynet-max25/processed/\n",
            "  inflating: download/datasets/publaynet-max25/processed/pre_transform.pt  \n",
            "  inflating: download/datasets/publaynet-max25/processed/val.pt  \n",
            "  inflating: download/datasets/publaynet-max25/processed/test.pt  \n",
            "  inflating: download/datasets/publaynet-max25/processed/train.pt  \n",
            "  inflating: download/datasets/publaynet-max25/processed/pre_filter.pt  \n",
            "   creating: download/datasets/publaynet-max25/raw/\n",
            "   creating: download/clustering_weights/\n",
            "  inflating: download/clustering_weights/publaynet_max25_kmeans_train_clusters.pkl  \n",
            "  inflating: download/clustering_weights/rico25_max25_kmeans_train_clusters.pkl  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyOdADQK98kx",
        "outputId": "7c012db3-06d0-42ed-a9d3-f6ca23b48b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/layout-dm/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install omegaconf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "Kyz2cvY49_f5",
        "outputId": "0249233c-2431-4988-a219-77510f115f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from omegaconf)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=6f8df19fe804a8af38190bb5779f4c44bbfa756a9c5389d8026f50fc8c1572d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "80dfbc99367647b9849f3411f4f74a30"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMzsC1px97IO",
        "outputId": "043a8b4e-505b-4a1c-bd32-f8919f614abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.3.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hydra-core"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH0PuE4B_IfS",
        "outputId": "ec24d451-d597-40e5-d894-f451b23ab1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core) (24.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.1)\n",
            "Installing collected packages: hydra-core\n",
            "Successfully installed hydra-core-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l0ohKpEBANy",
        "outputId": "4428b957-81de-470a-f194-de770b9341ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vmRwTklAgFm",
        "outputId": "0da56c14-8124-4628-c09c-f1772d438782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/layout-dm/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd trainer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F46XUJDAeK-",
        "outputId": "d5e8e77c-4c53-4f7f-a42c-288e1df843d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/layout-dm/src/trainer/trainer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp -r ../../../../layout-dm ../../../../drive/MyDrive/"
      ],
      "metadata": {
        "id": "EI8lZbWKBvEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8W2E6IgBtLm",
        "outputId": "db8817a2-29dd-4890-f6e3-c8a24a9c19f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mtrainer\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVOT73hkNTpv",
        "outputId": "e22411a6-0185-427d-8be8-46a2a8c76695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/layout-dm/src/trainer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "script_directory = os.getcwd()\n",
        "print(script_directory)\n",
        "module_dir = os.path.join(script_directory, 'relative/path/to/module')\n",
        "sys.path.append(module_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h0E5Cu0D38s",
        "outputId": "cd96f16e-a02b-4bae-90f5-b33a7906bb02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/layout-dm/src/trainer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "import torch\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "import torchvision.transforms as T\n",
        "from fsspec.core import url_to_fs\n",
        "from hydra.utils import instantiate\n",
        "from data.util import AddCanvasElement, AddRelationConstraints, sparse_to_dense\n",
        "from global_configs import DATASET_DIR, JOB_DIR\n",
        "from helpers.layout_tokenizer import LayoutSequenceTokenizer\n",
        "from helpers.sampling import SAMPLING_CONFIG_DICT\n",
        "from helpers.task import get_cond, filter_canvas\n",
        "from helpers.visualization import save_gif, save_image, save_label, save_label_with_size, save_relation\n",
        "from hydra_configs import TestConfig\n",
        "\n",
        "SIZE = (360, 240)\n",
        "\n",
        "# user tunable parameters\n",
        "# cond_type, W_CANVAS = \"relation\", True  # uncomment this line if you want to try relation task\n",
        "cond_type, W_CANVAS = \"cwh\", False  # choices: unconditional, c, cwh, partial, refinement\n",
        "n_samples = 4  # num. of samples to generate at once\n",
        "target_index = 0  # index of real data, partial fields in it are used for conditional generation\n",
        "\n",
        "job_dir = os.path.join(JOB_DIR, \"layoutdm_publaynet/0\")\n",
        "\n",
        "config_path = os.path.join(job_dir, \"config.yaml\")\n",
        "fs, _ = url_to_fs(config_path)\n",
        "if fs.exists(config_path):\n",
        "    with fs.open(config_path, \"rb\") as file_obj:\n",
        "        train_cfg = OmegaConf.load(file_obj)\n",
        "else:\n",
        "    raise FileNotFoundError\n",
        "train_cfg.dataset.dir = DATASET_DIR\n",
        "\n",
        "test_cfg = OmegaConf.structured(TestConfig)\n",
        "test_cfg.cond = cond_type\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "sampling_cfg = OmegaConf.structured(SAMPLING_CONFIG_DICT[test_cfg.sampling])  # NOTE: you may change sampling algorithm\n",
        "OmegaConf.set_struct(sampling_cfg, False)\n",
        "\n",
        "# initialize data and model\n",
        "tokenizer = LayoutSequenceTokenizer(\n",
        "    data_cfg=train_cfg.data, dataset_cfg=train_cfg.dataset\n",
        ")\n",
        "model = instantiate(train_cfg.model)(\n",
        "    backbone_cfg=train_cfg.backbone, tokenizer=tokenizer\n",
        ").to(device)\n",
        "model_path = os.path.join(job_dir, \"best_model.pt\")\n",
        "with fs.open(model_path, \"rb\") as file_obj:\n",
        "    model.load_state_dict(torch.load(file_obj))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "sampling_cfg = model.aggregate_sampling_settings(sampling_cfg, test_cfg)\n",
        "\n",
        "if W_CANVAS:\n",
        "    # add canvas and shift label id to load relation gts\n",
        "    assert cond_type == \"relation\"\n",
        "    transform = T.Compose([\n",
        "        AddCanvasElement(),\n",
        "        AddRelationConstraints(edge_ratio=0.1),\n",
        "    ])\n",
        "else:\n",
        "    assert cond_type != \"relation\"\n",
        "    transform = None\n",
        "dataset = instantiate(train_cfg.dataset)(split=\"test\", transform=transform)\n",
        "save_kwargs = {\n",
        "    \"colors\": dataset.colors, \"names\": dataset.labels,\n",
        "    \"canvas_size\": SIZE, \"use_grid\": True,\n",
        "    # \"draw_label\": True,\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# load target data and visualize GT\n",
        "bbox, label, _, mask = sparse_to_dense(dataset[target_index])\n",
        "gt_cond = model.tokenizer.encode(\n",
        "    {\"label\": label, \"mask\": mask, \"bbox\": bbox}\n",
        ")\n",
        "if \"bos\" in tokenizer.special_tokens:\n",
        "    gt = model.tokenizer.decode(gt_cond[\"seq\"][:, 1:])\n",
        "else:\n",
        "    gt = model.tokenizer.decode(gt_cond[\"seq\"])\n",
        "if W_CANVAS:\n",
        "    gt = filter_canvas(gt)  # remove canvas attributes before visualization\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(save_image(gt[\"bbox\"], gt[\"label\"], gt[\"mask\"], **save_kwargs))\n",
        "\n",
        "\n",
        "\n",
        "### Unconditional Generation\n",
        "\n",
        "assert cond_type == \"unconditional\"\n",
        "pred = model.sample(batch_size=n_samples, cond=None, sampling_cfg=sampling_cfg)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(save_image(pred[\"bbox\"], pred[\"label\"], pred[\"mask\"], **save_kwargs))\n",
        "\n",
        "### Conditional Generation\n",
        "\n",
        "#### Prediction\n",
        "\n",
        "cond = get_cond(\n",
        "    batch=dataset[target_index],\n",
        "    tokenizer=model.tokenizer,\n",
        "    cond_type=cond_type,\n",
        "    model_type=type(model).__name__,\n",
        ")\n",
        "pred = model.sample(batch_size=n_samples, cond=cond, sampling_cfg=sampling_cfg)\n",
        "\n",
        "\n",
        "#### Visualization of conditional inputs\n",
        "\n",
        "\n",
        "plt.axis(\"off\")\n",
        "input_ = model.tokenizer.decode(cond[\"seq\"].cpu())\n",
        "mask = pred[\"mask\"][0]\n",
        "label, bbox = pred[\"label\"][0][mask], pred[\"bbox\"][0][mask]\n",
        "if cond_type == \"c\":\n",
        "    plt.imshow(save_label(label, **save_kwargs))\n",
        "elif cond_type == \"cwh\":\n",
        "    plt.imshow(save_label_with_size(label, bbox, **save_kwargs))\n",
        "elif cond_type == \"relation\":\n",
        "    data = cond[\"batch_w_canvas\"]\n",
        "    edge_attr = to_dense_adj(data.edge_index, data.batch, data.edge_attr)\n",
        "    plt.imshow(save_relation(label_with_canvas=data.y.cpu(), edge_attr=edge_attr.cpu()[0], **save_kwargs))\n",
        "elif cond_type  == \"partial\":\n",
        "    plt.imshow(save_image(input_[\"bbox\"], input_[\"label\"], input_[\"mask\"], **save_kwargs))\n",
        "elif cond_type == \"refinement\":\n",
        "    noisy_input = model.tokenizer.decode(cond[\"seq_orig\"].cpu())\n",
        "    plt.imshow(save_image(noisy_input[\"bbox\"][0:1], noisy_input[\"label\"][0:1], noisy_input[\"mask\"][0:1], **save_kwargs))\n",
        "\n",
        "\n",
        "#### Visualization of outputs\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "ax.set_axis_off()\n",
        "ax.imshow(save_image(pred[\"bbox\"], pred[\"label\"], pred[\"mask\"], **save_kwargs, nrow=int(math.sqrt(n_samples) * 2)))\n",
        "\n",
        "\n",
        "#### Make GIF for Unconditional Generation\n",
        "\n",
        "new_save_kwargs = copy.deepcopy(save_kwargs)\n",
        "new_save_kwargs.pop(\"use_grid\")\n",
        "ids_list = model.model.sample(\n",
        "    batch_size=4,\n",
        "    sampling_cfg=sampling_cfg,\n",
        "    get_intermediate_results=True,\n",
        ")\n",
        "images = []\n",
        "for ids in ids_list:\n",
        "    layouts = model.tokenizer.decode(ids)\n",
        "    image = save_image(\n",
        "        layouts[\"bbox\"],\n",
        "        layouts[\"label\"],\n",
        "        layouts[\"mask\"],\n",
        "        **new_save_kwargs\n",
        "    )\n",
        "    images.append(image)\n",
        "N_step = len(images)\n",
        "images = images[int(0.5*N_step):]\n",
        "save_gif(images, \"../tmp/animation/{}.gif\")\n",
        "\n",
        "\n",
        "\n",
        "#### Dump colors of all labels\n",
        "\n",
        "\n",
        "labels = []\n",
        "for i, name in enumerate(save_kwargs[\"names\"]):\n",
        "    if \"_cutout\" in name:\n",
        "        continue\n",
        "    else:\n",
        "        labels.append(i)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(save_label(labels, **save_kwargs))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "id": "OmBsMZB69UlC",
        "outputId": "a26fc6b5-2c4e-411a-d238-8b6f6787a4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator KMeans from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InstantiationException",
          "evalue": "Error locating target 'trainer.models.layoutdm.LayoutDM', set env var HYDRA_FULL_ERROR=1 to see chained exception.\nfull_key: model",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py\u001b[0m in \u001b[0;36m_locate\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc_attr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'trainer' has no attribute 'models'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py\u001b[0m in \u001b[0;36m_locate\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'trainer.models'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py\u001b[0m in \u001b[0;36m_resolve_target\u001b[0;34m(target, full_key)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_locate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py\u001b[0m in \u001b[0;36m_locate\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc_import\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m                     raise ImportError(\n\u001b[0m\u001b[1;32m    654\u001b[0m                         \u001b[0;34mf\"Error loading '{path}':\\n{repr(exc_import)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Error loading 'trainer.models.layoutdm.LayoutDM':\nModuleNotFoundError(\"No module named 'trainer.models'\")\nAre you sure that 'models' is importable from module 'trainer'?",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-345fd3fadd2a>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mdata_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m )\n\u001b[0;32m---> 50\u001b[0;31m model = instantiate(train_cfg.model)(\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mbackbone_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m ).to(device)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py\u001b[0m in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0m_partial_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPARTIAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         return instantiate_node(\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_recursive_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_convert_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_partial_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py\u001b[0m in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mexclude_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"_target_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_convert_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_recursive_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_partial_\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0m_target_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_resolve_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mis_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_partial_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hydra/_internal/instantiate/_instantiate2.py\u001b[0m in \u001b[0;36m_resolve_target\u001b[0;34m(target, full_key)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfull_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\nfull_key: {full_key}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInstantiationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Expected a callable target, got '{target}' of type '{type(target).__name__}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInstantiationException\u001b[0m: Error locating target 'trainer.models.layoutdm.LayoutDM', set env var HYDRA_FULL_ERROR=1 to see chained exception.\nfull_key: model"
          ]
        }
      ]
    }
  ]
}