{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHslI2g4u0Ug",
        "outputId": "28d77207-8f1c-497f-9095-9e28707d1632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 10.0.1\n",
            "    Uninstalling pyarrow-10.0.1:\n",
            "      Successfully uninstalled pyarrow-10.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.17.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhM0w3muvCCX",
        "outputId": "d61de693-726f-4a94-fbb2-e061cd32bb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.2.0.post0-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.9/800.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.9.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch_lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch_lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch_lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch_lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.10.1 pytorch_lightning-2.2.0.post0 torchmetrics-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kjHQxNwGRlg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from typing import Dict, List, Optional, OrderedDict, Tuple\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
        "#from pytorch_lightning.utilities.seed import seed_everything\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id9U9vhaGRlh"
      },
      "outputs": [],
      "source": [
        "ALL_IMAGES = []\n",
        "\n",
        "img_size = 256\n",
        "batch_size = 8\n",
        "normalize = [(0.5), (0.5)]\n",
        "latent_size = 256\n",
        "data_dir = \"ChainYo/rvl-cdip-invoice\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trN3VkylGRlh"
      },
      "outputs": [],
      "source": [
        "transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(img_size),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(*normalize)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4APBGncGRlh"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(data_dir, split=\"train\")\n",
        "print(dataset)\n",
        "\n",
        "labels = dataset.features[\"label\"].names\n",
        "num_labels = dataset.features[\"label\"].num_classes\n",
        "\n",
        "\n",
        "def preprocess_data(examples):\n",
        "    examples[\"tr_image\"] = [transforms(img) for img in examples[\"image\"]]\n",
        "    del examples[\"image\"]\n",
        "    return examples\n",
        "\n",
        "\n",
        "transformed_dataset = dataset.with_transform(preprocess_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohCdXBsdGRli"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    transformed_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkU8tKX9GRli",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "ff08acc5-2417-437a-c873-a5ecf4c78d22"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Returns' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a9df601ad46b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mReturns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Returns' is not defined"
          ]
        }
      ],
      "source": [
        "def denormalize(input_image_tensors: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Denormalizes the input image tensors.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_image_tensors : torch.Tensor\n",
        "        The input image tensors.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        The denormalized image tensors.\n",
        "    \"\"\"\n",
        "    return input_image_tensors.mul(normalize[1]).add(normalize[0])\n",
        "\n",
        "\n",
        "def save_samples(index: int, sample_images: torch.Tensor) -> None:\n",
        "    \"\"\"\n",
        "    Saves the generated samples.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    index : int\n",
        "        The index of the sample.\n",
        "    sample_images : torch.Tensor\n",
        "        The generated sample images.\n",
        "    \"\"\"\n",
        "    fake_name = f\"generated-images-{index}.png\"\n",
        "    save_image(denormalize(sample_images[-64:]), os.path.join(\"generated\", fake_name), nrow=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjbqpcCMGRli"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size: Optional[int] = 64,\n",
        "        channels: Optional[int] = 3,\n",
        "        kernel_size: Optional[int] = 4,\n",
        "        stride: Optional[int] = 2,\n",
        "        padding: Optional[int] = 1,\n",
        "        negative_slope: Optional[float] = 0.2,\n",
        "        bias: Optional[bool] = False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the discriminator.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        hidden_size : int, optional\n",
        "            The input size. (the default is 64)\n",
        "        channels : int, optional\n",
        "            The number of channels. (default: 3)\n",
        "        kernel_size : int, optional\n",
        "            The kernal size. (default: 4)\n",
        "        stride : int, optional\n",
        "            The stride. (default: 2)\n",
        "        padding : int, optional\n",
        "            The padding. (default: 1)\n",
        "        negative_slope : float, optional\n",
        "            The negative slope. (default: 0.2)\n",
        "        bias : bool, optional\n",
        "            Whether to use bias. (default: False)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.channels = channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.negative_slope = negative_slope\n",
        "        self.bias = bias\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Conv2d(\n",
        "                    self.channels, self.hidden_size,\n",
        "                    kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "                ),\n",
        "            ),\n",
        "            nn.LeakyReLU(self.negative_slope, inplace=True),\n",
        "\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Conv2d(\n",
        "                    hidden_size, hidden_size * 2,\n",
        "                    kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "                ),\n",
        "            ),\n",
        "            nn.BatchNorm2d(hidden_size * 2),\n",
        "            nn.LeakyReLU(self.negative_slope, inplace=True),\n",
        "\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Conv2d(\n",
        "                    hidden_size * 2, hidden_size * 4,\n",
        "                    kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "                ),\n",
        "            ),\n",
        "            nn.BatchNorm2d(hidden_size * 4),\n",
        "            nn.LeakyReLU(self.negative_slope, inplace=True),\n",
        "\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Conv2d(\n",
        "                    hidden_size * 4, hidden_size * 8,\n",
        "                    kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "                ),\n",
        "            ),\n",
        "            nn.BatchNorm2d(hidden_size * 8),\n",
        "            nn.LeakyReLU(self.negative_slope, inplace=True),\n",
        "\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Conv2d(\n",
        "                    hidden_size * 8, hidden_size * 16,\n",
        "                    kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "                ),\n",
        "            ),\n",
        "            nn.BatchNorm2d(hidden_size * 16),\n",
        "            nn.LeakyReLU(self.negative_slope, inplace=True),\n",
        "\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Conv2d(\n",
        "                    hidden_size * 16, hidden_size * 32,\n",
        "                    kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "                ),\n",
        "            ),\n",
        "            nn.BatchNorm2d(hidden_size * 32),\n",
        "            nn.LeakyReLU(self.negative_slope, inplace=True),\n",
        "\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Conv2d(hidden_size * 32, 1, kernel_size=4, stride=1, padding=0, bias=self.bias), # output size: (1, 1, 1)\n",
        "            ),\n",
        "            nn.Flatten(),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, input_img: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward propagation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_img : torch.Tensor\n",
        "            The input image.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The output.\n",
        "        \"\"\"\n",
        "        logits = self.model(input_img)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReXu8M5UGRlj"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size: Optional[int] = 64,\n",
        "        latent_size: Optional[int] = 128,\n",
        "        channels: Optional[int] = 3,\n",
        "        kernel_size: Optional[int] = 4,\n",
        "        stride: Optional[int] = 2,\n",
        "        padding: Optional[int] = 1,\n",
        "        bias: Optional[bool] = False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the generator.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        hidden_size : int, optional\n",
        "            The hidden size. (default: 64)\n",
        "        latent_size : int, optional\n",
        "            The latent size. (default: 128)\n",
        "        channels : int, optional\n",
        "            The number of channels. (default: 3)\n",
        "        kernel_size : int, optional\n",
        "            The kernel size. (default: 4)\n",
        "        stride : int, optional\n",
        "            The stride. (default: 2)\n",
        "        padding : int, optional\n",
        "            The padding. (default: 1)\n",
        "        bias : bool, optional\n",
        "            Whether to use bias. (default: False)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.latent_size = latent_size\n",
        "        self.channels = channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.bias = bias\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                self.latent_size, self.hidden_size * 32,\n",
        "                kernel_size=self.kernel_size, stride=1, padding=0, bias=self.bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.hidden_size * 32),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(\n",
        "                self.hidden_size * 32, self.hidden_size * 16,\n",
        "                kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.hidden_size * 16),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(\n",
        "                self.hidden_size * 16, self.hidden_size * 8,\n",
        "                kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.hidden_size * 8),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(\n",
        "                self.hidden_size * 8, self.hidden_size * 4,\n",
        "                kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.hidden_size * 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(\n",
        "                self.hidden_size * 4, self.hidden_size * 2,\n",
        "                kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.hidden_size * 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(\n",
        "                self.hidden_size * 2, self.hidden_size,\n",
        "                kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "            ),\n",
        "            nn.BatchNorm2d(self.hidden_size),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(\n",
        "                self.hidden_size, self.channels,\n",
        "                kernel_size=self.kernel_size, stride=self.stride, padding=self.padding, bias=self.bias\n",
        "            ),\n",
        "            nn.Tanh() # output size: (channels, 64, 64)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, input_noise: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward propagation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_noise : torch.Tensor\n",
        "            The input image.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The output.\n",
        "        \"\"\"\n",
        "        fake_img = self.model(input_noise)\n",
        "        return fake_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfe-gKo7GRlj"
      },
      "outputs": [],
      "source": [
        "class DocuGAN(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size: Optional[int] = 64,\n",
        "        latent_size: Optional[int] = 128,\n",
        "        num_channel: Optional[int] = 3,\n",
        "        learning_rate: Optional[float] = 0.0002,\n",
        "        batch_size: Optional[int] = 128,\n",
        "        bias1: Optional[float] = 0.5,\n",
        "        bias2: Optional[float] = 0.999,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the LightningGan.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        hidden_size : int, optional\n",
        "            The hidden size. (default: 64)\n",
        "        latent_size : int, optional\n",
        "            The latent size. (default: 128)\n",
        "        num_channel : int, optional\n",
        "            The number of channels. (default: 3)\n",
        "        learning_rate : float, optional\n",
        "            The learning rate. (default: 0.0002)\n",
        "        batch_size : int, optional\n",
        "            The batch size. (default: 128)\n",
        "        bias1 : float, optional\n",
        "            The bias1. (default: 0.5)\n",
        "        bias2 : float, optional\n",
        "            The bias2. (default: 0.999)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.latent_size = latent_size\n",
        "        self.num_channel = num_channel\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.bias1 = bias1\n",
        "        self.bias2 = bias2\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.validation = torch.randn(self.batch_size, self.latent_size, 1, 1)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.generator = Generator(\n",
        "            latent_size=self.latent_size, channels=self.num_channel, hidden_size=self.hidden_size\n",
        "        )\n",
        "        self.generator.apply(self.weights_init)\n",
        "\n",
        "        self.discriminator = Discriminator(channels=self.num_channel, hidden_size=self.hidden_size)\n",
        "        self.discriminator.apply(self.weights_init)\n",
        "\n",
        "        # self.model = InceptionV3() # For FID metric\n",
        "\n",
        "\n",
        "    def weights_init(self, m: nn.Module) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the weights.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        m : nn.Module\n",
        "            The module.\n",
        "        \"\"\"\n",
        "        classname = m.__class__.__name__\n",
        "        if classname.find(\"Conv\") != -1:\n",
        "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        elif classname.find(\"BatchNorm\") != -1:\n",
        "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "            nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self) -> Tuple[List[torch.optim.Optimizer], List]:\n",
        "        \"\"\"\n",
        "        Configures the optimizers.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tuple[List[torch.optim.Optimizer], List]\n",
        "            The optimizers and the LR schedulers.\n",
        "        \"\"\"\n",
        "        opt_generator = torch.optim.Adam(\n",
        "            self.generator.parameters(), lr=self.learning_rate, betas=(self.bias1, self.bias2)\n",
        "        )\n",
        "        opt_discriminator = torch.optim.Adam(\n",
        "            self.discriminator.parameters(), lr=self.learning_rate, betas=(self.bias1, self.bias2)\n",
        "        )\n",
        "        return [opt_generator, opt_discriminator], []\n",
        "\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward propagation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        z : torch.Tensorh\n",
        "            The latent vector.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The output.\n",
        "        \"\"\"\n",
        "        return self.generator(z)\n",
        "\n",
        "\n",
        "    def training_step(\n",
        "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int, optimizer_idx: int\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Training step.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch : Tuple[torch.Tensor, torch.Tensor]\n",
        "            The batch.\n",
        "        batch_idx : int\n",
        "            The batch index.\n",
        "        optimizer_idx : int\n",
        "            The optimizer index.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            The training loss.\n",
        "        \"\"\"\n",
        "        real_images = batch[\"tr_image\"]\n",
        "\n",
        "        if optimizer_idx == 0: # Only train the generator\n",
        "            fake_random_noise = torch.randn(self.batch_size, self.latent_size, 1, 1)\n",
        "            fake_random_noise = fake_random_noise.type_as(real_images)\n",
        "            fake_images = self(fake_random_noise)\n",
        "\n",
        "            # Try to fool the discriminator\n",
        "            preds = self.discriminator(fake_images)\n",
        "            loss = self.criterion(preds, torch.ones_like(preds))\n",
        "            self.log(\"g_loss\", loss, on_step=False, on_epoch=True)\n",
        "\n",
        "            tqdm_dict = {\"g_loss\": loss}\n",
        "            output = OrderedDict({\"loss\": loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict})\n",
        "            return output\n",
        "\n",
        "        elif optimizer_idx == 1: # Only train the discriminator\n",
        "            real_preds = self.discriminator(real_images)\n",
        "            real_loss = self.criterion(real_preds, torch.ones_like(real_preds))\n",
        "\n",
        "            # Generate fake images\n",
        "            real_random_noise = torch.randn(self.batch_size, self.latent_size, 1, 1)\n",
        "            real_random_noise = real_random_noise.type_as(real_images)\n",
        "            fake_images = self(real_random_noise)\n",
        "\n",
        "            # Pass fake images though discriminator\n",
        "            fake_preds = self.discriminator(fake_images)\n",
        "            fake_loss = self.criterion(fake_preds, torch.zeros_like(fake_preds))\n",
        "\n",
        "            # Update discriminator weights\n",
        "            loss = real_loss + fake_loss\n",
        "            self.log(\"d_loss\", loss, on_step=False, on_epoch=True)\n",
        "\n",
        "            tqdm_dict = {\"d_loss\": loss}\n",
        "            output = OrderedDict({\"loss\": loss, \"progress_bar\": tqdm_dict, \"log\": tqdm_dict})\n",
        "            return output\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"\n",
        "        Called at the end of an epoch.\n",
        "        \"\"\"\n",
        "        z = self.validation.type_as(self.generator.model[0].weight)\n",
        "        sample_images = self(z)\n",
        "        ALL_IMAGES.append(sample_images.detach().cpu())\n",
        "        save_samples(self.current_epoch, sample_images)\n",
        "        self.logger[1].log_image(key=f\"images-epoch{self.current_epoch}\", images=[sample_images])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p-aqvzZGRlj",
        "outputId": "a7fab76f-98bc-4ff1-f9bd-d4bf366e3493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DocuGAN(\n",
            "  (criterion): BCELoss()\n",
            "  (generator): Generator(\n",
            "    (model): Sequential(\n",
            "      (0): ConvTranspose2d(256, 8192, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): ConvTranspose2d(8192, 4096, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (4): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): ConvTranspose2d(4096, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): ConvTranspose2d(2048, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (14): ReLU(inplace=True)\n",
            "      (15): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (17): ReLU(inplace=True)\n",
            "      (18): ConvTranspose2d(256, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (19): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (discriminator): Discriminator(\n",
            "    (model): Sequential(\n",
            "      (0): Conv2d(1, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (2): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (5): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (8): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (9): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (11): Conv2d(2048, 4096, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (12): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (14): Conv2d(4096, 8192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (15): BatchNorm2d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (17): Conv2d(8192, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "      (18): Flatten(start_dim=1, end_dim=-1)\n",
            "      (19): Sigmoid()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#seed_everything(42)\n",
        "gpus = 1 if torch.cuda.is_available() else 0\n",
        "\n",
        "tf_logger = TensorBoardLogger(\"logs\", name=\"docugan\")\n",
        "#wandb_logger = WandbLogger(project=\"docugan\")\n",
        "\n",
        "model = DocuGAN(hidden_size=256, num_channel=1, latent_size=256, batch_size=8)\n",
        "\n",
        "\n",
        "print(model)\n",
        "# trainer = pl.Trainer(\n",
        "#     gpus=gpus,\n",
        "#     max_epochs=500,\n",
        "#     progress_bar_refresh_rate=25,\n",
        "#     logger=[tf_logger, wandb_logger],\n",
        "# )\n",
        "# trainer.fit(model, train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X5RMnuYGRlk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "5406f92c8d19fda445423ffdaa7070bacd3ced4c073d12b808912f01e69056e3"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('gan-bird')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}